{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T06:21:33.615245Z",
     "iopub.status.busy": "2025-03-24T06:21:33.614932Z",
     "iopub.status.idle": "2025-03-24T06:21:38.827785Z",
     "shell.execute_reply": "2025-03-24T06:21:38.827152Z",
     "shell.execute_reply.started": "2025-03-24T06:21:33.615219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "# from google.colab import drive\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler #randomly shuffles the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the transform functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-24T06:21:44.758533Z",
     "iopub.status.busy": "2025-03-24T06:21:44.758143Z",
     "iopub.status.idle": "2025-03-24T06:21:44.764566Z",
     "shell.execute_reply": "2025-03-24T06:21:44.763737Z",
     "shell.execute_reply.started": "2025-03-24T06:21:44.758509Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform2 = transforms.Compose([#vgg16\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(), # ToTensor image ko convert karta hai pixelated values ye pytorch tensor me ie [0,1]\n",
    "    transforms.Normalize(  #Normalize scale karta hai image ko [-1,1] me\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "\n",
    "transform3 = transforms.Compose([          #resnet\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]\n",
    "                         )\n",
    "])\n",
    "\n",
    "transform4 = transforms.Compose([          #mobilenetv2\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T06:21:47.216662Z",
     "iopub.status.busy": "2025-03-24T06:21:47.216388Z",
     "iopub.status.idle": "2025-03-24T06:21:56.660330Z",
     "shell.execute_reply": "2025-03-24T06:21:56.659470Z",
     "shell.execute_reply.started": "2025-03-24T06:21:47.216640Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 3777\n",
      "    Root location: /kaggle/input/mepco-tropic-leaf/MepcoTropicLeaf-V1/Database\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(299, 299), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 3777\n",
      "    Root location: /kaggle/input/mepco-tropic-leaf/MepcoTropicLeaf-V1/Database\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 3777\n",
      "    Root location: /kaggle/input/mepco-tropic-leaf/MepcoTropicLeaf-V1/Database\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(299, 299), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For google colab \n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# dataset_vgg=datasets.ImageFolder(\"/content/drive/MyDrive/patta /archive/MepcoTropicLeaf-V1/Database\", transform=transform2)\n",
    "# dataset_mobilenet=datasets.ImageFolder(\"/content/drive/MyDrive/patta /archive/MepcoTropicLeaf-V1/Database\", transform=transform4)\n",
    "# dataset_resnet=datasets.ImageFolder(\"/content/drive/MyDrive/patta /archive/MepcoTropicLeaf-V1/Database\", transform=transform3)\n",
    "\n",
    "\n",
    "# On laptop \n",
    "# dataset_vgg=datasets.ImageFolder(\"C:\\\\Users\\\\hardi\\\\Downloads\\\\archive\\\\MepcoTropicLeaf-V1\\\\Database\", transform=transform2)\n",
    "# dataset_mobilenet=datasets.ImageFolder(\"C:\\\\Users\\\\hardi\\\\Downloads\\\\archive\\\\MepcoTropicLeaf-V1\\\\Database\", transform=transform4)\n",
    "# dataset_resnet=datasets.ImageFolder(\"C:\\\\Users\\\\hardi\\\\Downloads\\\\archive\\\\MepcoTropicLeaf-V1\\\\Database\", transform=transform3)\n",
    "\n",
    "#for kaggle \n",
    "\n",
    "dataset_vgg=datasets.ImageFolder(\"/kaggle/input/mepco-tropic-leaf/MepcoTropicLeaf-V1/Database\", transform=transform2)\n",
    "dataset_mobilenet=datasets.ImageFolder(\"/kaggle/input/mepco-tropic-leaf/MepcoTropicLeaf-V1/Database\", transform=transform4)\n",
    "dataset_resnet=datasets.ImageFolder(\"/kaggle/input/mepco-tropic-leaf/MepcoTropicLeaf-V1/Database\", transform=transform3)\n",
    "\n",
    "\n",
    "print(dataset_vgg)\n",
    "print(dataset_mobilenet)\n",
    "print(dataset_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T06:22:01.773973Z",
     "iopub.status.busy": "2025-03-24T06:22:01.773669Z",
     "iopub.status.idle": "2025-03-24T06:22:01.780868Z",
     "shell.execute_reply": "2025-03-24T06:22:01.779872Z",
     "shell.execute_reply.started": "2025-03-24T06:22:01.773946Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train size : 1585\n",
      "length of validation size : 1058\n",
      "length of test size : 1134\n"
     ]
    }
   ],
   "source": [
    "\n",
    "indices=list(range(len(dataset_vgg))) # dataset ko numerate karne ke liye\n",
    "split=int(np.floor(0.70*len(dataset_vgg)))\n",
    "validation=int(np.floor(0.60*split))\n",
    "\n",
    "# agar tmre pass 100 samples hai\n",
    "# toh split=70(ie 70% of the dataset)-> ee use hoga training and validation ke liye; remaining (30)30% used hoga as test set\n",
    "# tb validation=42 (ie 60% of the dataset)-> ee use hoga for training ke liye; remaining (28)40% used hoga as Validation set\n",
    "# toh phir training= 42%; validation= 28%; test=30%\n",
    "\n",
    "print(f\"length of train size : {validation}\")\n",
    "print(f\"length of validation size : {split-validation}\")\n",
    "print(f\"length of test size : {len(dataset_vgg)-split}\")\n",
    "\n",
    "np.random.shuffle(indices) # dataset me randomness laane ke liye\n",
    "\n",
    "# ab actual splitting\n",
    "train_indices, validation_indices, test_indices = (\n",
    "    indices[:validation], # [:5]->0,1,2,3,4\n",
    "    indices[validation:split],# [1:3]->1,2\n",
    "    indices[split:],# [2:]-> 2,3,4,5,........\n",
    ")\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "validation_sampler = SubsetRandomSampler(validation_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "# print(list(train_indices))\n",
    "# print(list(validation_indices))\n",
    "# print(list(test_indices))\n",
    "\n",
    "# print(list(train_sampler))\n",
    "# print(list(validation_sampler))\n",
    "# print(list(test_sampler))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No. of unique features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T06:22:05.801000Z",
     "iopub.status.busy": "2025-03-24T06:22:05.800725Z",
     "iopub.status.idle": "2025-03-24T06:22:05.806388Z",
     "shell.execute_reply": "2025-03-24T06:22:05.805450Z",
     "shell.execute_reply.started": "2025-03-24T06:22:05.800976Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "['Asthma Plant.zip', 'Avaram.zip', 'Balloon vine.zip', 'Bellyache bush (Green).zip', 'Benghal dayflower.zip', 'Big Caltrops.zip', 'Black-Honey Shrub.zip', 'Bristly Wild Grape.zip', 'Butterfly Pea.zip', 'Cape Gooseberry.zip', 'Common Wireweed.zip', 'Country Mallow.zip', 'Crown flower.zip', 'Green Chireta.zip', 'Holy Basil.zip', 'Indian CopperLeaf.zip', 'Indian Jujube.zip', 'Indian Sarsaparilla.zip', 'Indian Stinging Nettle.zip', 'Indian Thornapple.zip', 'Indian wormwood.zip', 'Ivy Gourd.zip', 'Kokilaksha.zip', 'Land Caltrops (Bindii).zip', 'Madagascar Periwinkle.zip', 'Madras Pea Pumpkin.zip', 'Malabar Catmint.zip', 'Mexican Mint.zip', 'Mexican Prickly Poppy.zip', 'Mountain Knotgrass.zip', 'Nalta Jute.zip', 'Night blooming Cereus.zip', 'Panicled Foldwing.zip', 'Prickly Chaff Flower.zip', 'Punarnava.zip', 'Purple Fruited Pea Eggplant.zip', 'Purple Tephrosia.zip', 'Rosary Pea.zip', 'Shaggy button weed.zip', 'Small Water Clover.zip', 'Spiderwisp.zip', 'Square Stalked Vine.zip', 'Stinking Passionflower.zip', 'Sweet Basil.zip', 'Sweet flag.zip', 'Tinnevelly Senna.zip', 'Trellis Vine.zip', 'Velvet bean.zip', 'coatbuttons.zip', 'heart-leaved moonseed.zip']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    }
   ],
   "source": [
    "targets_size = len(dataset_vgg.class_to_idx)# finding the total unique classes and storing it\n",
    "print(targets_size)\n",
    "print(list(dataset_vgg.class_to_idx.keys()))\n",
    "num_classes_list = list(dataset_vgg.class_to_idx.values())# now numerating them\n",
    "print(num_classes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T06:22:08.327634Z",
     "iopub.status.busy": "2025-03-24T06:22:08.327363Z",
     "iopub.status.idle": "2025-03-24T06:22:13.309508Z",
     "shell.execute_reply": "2025-03-24T06:22:13.308795Z",
     "shell.execute_reply.started": "2025-03-24T06:22:08.327613Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:02<00:00, 231MB/s]  \n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 112MB/s] \n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 177MB/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = models.vgg16(pretrained=True)#if pretrained=false, tb saare layers ko hmlog ko individually train karna hoga\n",
    "model2=models.mobilenet_v2(pretrained=True)\n",
    "model3=models.resnet18(pretrained=True)\n",
    "\n",
    "# model\n",
    "# model2\n",
    "# model3\n",
    "\n",
    "for params in model3.parameters():\n",
    "   params.requires_grad = True\n",
    "# resnet18 ke saare parameters ko trainable bana rhe hai; resnet ka feature extraction acha kaam karra hai isliye use krre plus accuracy bhi increase ho rha\n",
    "# mobilenet aur vgg complex models hai (more param and layers), agar isko(function) use kare toh model overfit ho sakta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting feature size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T06:22:15.616271Z",
     "iopub.status.busy": "2025-03-24T06:22:15.615934Z",
     "iopub.status.idle": "2025-03-24T06:22:15.621777Z",
     "shell.execute_reply": "2025-03-24T06:22:15.620796Z",
     "shell.execute_reply.started": "2025-03-24T06:22:15.616242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 25088\n",
      "2 1280\n",
      "3 3\n"
     ]
    }
   ],
   "source": [
    "n_features = model.classifier[0].in_features #vgg16; number of input features in the first fully connected layer\n",
    "print(1, n_features)\n",
    "n_features = model2.classifier[1].in_features #mobilenet; number of input features in the first fully connected layer\n",
    "print(2, n_features)\n",
    "n_features = model3.conv1.in_channels #resnet18; number of input features in the first convolutional layer\n",
    "print(3, n_features)\n",
    "\n",
    "# ee kyu krre?-> taaki pata chale ki input and output features pata chale\n",
    "# Last layer change karke model ko apne data pe train karre hai.\n",
    "# Pehle wali layers ko rakhne ka fayda->\n",
    "# Ye layers already trained hota h aur feature extraction achha kar leta h.\n",
    "# Sirf last layer train karne se kam computation time lagega.\n",
    "# Kam data hone par bhi model achha perform karega, kyunki pehle se trained layers use ho rahi hain.\n",
    "# Isko *Transfer Learning kehte hain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overriding the calculations to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T06:22:55.076429Z",
     "iopub.status.busy": "2025-03-24T06:22:55.076105Z",
     "iopub.status.idle": "2025-03-24T06:22:55.554975Z",
     "shell.execute_reply": "2025-03-24T06:22:55.553988Z",
     "shell.execute_reply.started": "2025-03-24T06:22:55.076402Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) #checking if GPU is available\n",
    "model.to(device)\n",
    "model2.to(device)\n",
    "model3.to(device)#shifting the model to 'device' for computing\n",
    "\n",
    "#summarizing the layers of all models; helps validate the model before training, avoiding errors later.\n",
    "\n",
    "# from torchsummary import summary\n",
    "# print(1, summary(model, (3, 224, 224)))\n",
    "# print(2, summary(model2, (3, 224, 224)))\n",
    "# print(3, summary(model3, (3, 224, 224)))\n",
    "\n",
    "#output shape [-1,c,h,w]\n",
    "#c->no of filters/ channels\n",
    "#h,w-> feature map size after operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T06:22:31.949096Z",
     "iopub.status.busy": "2025-03-24T06:22:31.948756Z",
     "iopub.status.idle": "2025-03-24T06:22:31.954680Z",
     "shell.execute_reply": "2025-03-24T06:22:31.953716Z",
     "shell.execute_reply.started": "2025-03-24T06:22:31.949033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()  # this include softmax + cross entropy loss\n",
    "# calculates the loss during training, which will be later used by backpropagation to imporove the models accuracy\n",
    "optimizer_vgg = torch.optim.Adam(model.parameters())\n",
    "optimizer_mobilenet= torch.optim.Adam(model2.parameters())\n",
    "optimizer_resnet = torch.optim.Adam(model3.parameters())\n",
    "#adam optimiser is used to optimise the models parameters(weights of the model) to minimise the loss and hence increase the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T06:22:37.286192Z",
     "iopub.status.busy": "2025-03-24T06:22:37.285836Z",
     "iopub.status.idle": "2025-03-24T06:22:37.291700Z",
     "shell.execute_reply": "2025-03-24T06:22:37.290790Z",
     "shell.execute_reply.started": "2025-03-24T06:22:37.286161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train_loader': transforms.Compose([\n",
    "        transforms.RandomAffine(degrees=10, translate=(0.05, 0.05), shear=5) , # image ko randomly rotate karne ke liye\n",
    "        transforms.ColorJitter(hue=0.05, saturation=0.05), # naam jo suggest karta hai\n",
    "        transforms.RandomHorizontalFlip(), #randomly image ko flip kar deta hai 50% probability saath\n",
    "        transforms.Grayscale(num_output_channels=1), #image is converted to black and white when =1; when=3 it is converted to fake RGB\n",
    "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=7)], p=0.2), # randomly applies Gaussian blur with probability=20%;\n",
    "                                                                                 # kernel size=7->moderate blur; 3->light blur; 15->heavy blur\n",
    "        transforms.ToTensor(),#image ko convert karta hai pixelated values ye pytorch tensor me ie [0,1]\n",
    "        transforms.Normalize((0.5,), (0.5,)),#pixelated values from [0,1] to [-1,1]\n",
    "    ]),\n",
    "    'validation_loader': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T06:22:40.267468Z",
     "iopub.status.busy": "2025-03-24T06:22:40.267185Z",
     "iopub.status.idle": "2025-03-24T06:22:40.273693Z",
     "shell.execute_reply": "2025-03-24T06:22:40.272710Z",
     "shell.execute_reply.started": "2025-03-24T06:22:40.267445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "#balances training speed and memory usage, as smaller trains slow and require less gpu, while larger batches train faster but require more GPU memory.\n",
    "#vgg\n",
    "train_loader_vgg = torch.utils.data.DataLoader(dataset_vgg, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader_vgg = torch.utils.data.DataLoader(dataset_vgg, batch_size=batch_size, sampler=test_sampler)\n",
    "validation_loader_vgg = torch.utils.data.DataLoader(dataset_vgg, batch_size=batch_size, sampler=validation_sampler)\n",
    "\n",
    "#mobilenet\n",
    "train_loader_mobilenet = torch.utils.data.DataLoader(dataset_mobilenet, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader_mobilenet = torch.utils.data.DataLoader(dataset_mobilenet, batch_size=batch_size, sampler=test_sampler)\n",
    "validation_loader_mobilenet = torch.utils.data.DataLoader(dataset_mobilenet, batch_size=batch_size, sampler=validation_sampler)\n",
    "\n",
    "#resnet\n",
    "train_loader_resnet = torch.utils.data.DataLoader(dataset_resnet, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader_resnet = torch.utils.data.DataLoader(dataset_resnet, batch_size=batch_size, sampler=test_sampler)\n",
    "validation_loader_resnet = torch.utils.data.DataLoader(dataset_resnet, batch_size=batch_size, sampler=validation_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T07:07:55.337517Z",
     "iopub.status.busy": "2025-03-24T07:07:55.337221Z",
     "iopub.status.idle": "2025-03-24T07:07:55.344188Z",
     "shell.execute_reply": "2025-03-24T07:07:55.343304Z",
     "shell.execute_reply.started": "2025-03-24T07:07:55.337493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, train_loader, test_laoder, epochs):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "\n",
    "    for e in range(epochs):\n",
    "\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer_vgg.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            train_loss.append(loss.item())  # torch to numpy world\n",
    "            loss.backward()\n",
    "            optimizer_vgg.step()\n",
    "\n",
    "        train_loss = np.mean(train_loss)\n",
    "\n",
    "        validation_loss = []\n",
    "\n",
    "        for inputs, targets in validation_loader_vgg:\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            output = model(inputs)\n",
    "\n",
    "            loss = criterion(output, targets)\n",
    "\n",
    "            validation_loss.append(loss.item())  # torch to numpy world\n",
    "\n",
    "        validation_loss = np.mean(validation_loss)\n",
    "\n",
    "        train_losses[e] = train_loss\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "\n",
    "        print(f\"Epoch : {e+1}/{epochs} Train_loss:{train_loss:.3f} Duration:{dt}\")\n",
    "\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T07:07:59.344477Z",
     "iopub.status.busy": "2025-03-24T07:07:59.344158Z",
     "iopub.status.idle": "2025-03-24T07:08:46.736668Z",
     "shell.execute_reply": "2025-03-24T07:08:46.735394Z",
     "shell.execute_reply.started": "2025-03-24T07:07:59.344450Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 694.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 110.12 MiB is free. Process 2513 has 14.63 GiB memory in use. Of the allocated memory 13.88 GiB is allocated by PyTorch, and 632.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-401de4f03094>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses_vgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_gd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_vgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader_vgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-382807e7f695>\u001b[0m in \u001b[0;36mbatch_gd\u001b[0;34m(model, criterion, train_loader, test_laoder, epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 694.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 110.12 MiB is free. Process 2513 has 14.63 GiB memory in use. Of the allocated memory 13.88 GiB is allocated by PyTorch, and 632.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "train_losses_vgg = batch_gd(model, criterion, train_loader_vgg, validation_loader_vgg, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T06:41:12.863741Z",
     "iopub.status.busy": "2025-03-24T06:41:12.863456Z",
     "iopub.status.idle": "2025-03-24T06:41:13.062079Z",
     "shell.execute_reply": "2025-03-24T06:41:13.061171Z",
     "shell.execute_reply.started": "2025-03-24T06:41:12.863718Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses_vgg , label = 'train_loss_vgg')\n",
    "plt.xlabel('No of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()#validation loss ke liye "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T06:41:19.750360Z",
     "iopub.status.busy": "2025-03-24T06:41:19.749904Z",
     "iopub.status.idle": "2025-03-24T06:41:19.758645Z",
     "shell.execute_reply": "2025-03-24T06:41:19.757288Z",
     "shell.execute_reply.started": "2025-03-24T06:41:19.750323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def accuracy(loader, model):\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    model.cuda()  # Move the model to GPU\n",
    "\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        outputs = model(inputs)  \n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        n_correct += (predictions == targets).sum().item()\n",
    "        n_total += targets.shape[0]\n",
    "\n",
    "    acc = n_correct / n_total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T06:41:55.532192Z",
     "iopub.status.busy": "2025-03-24T06:41:55.531823Z",
     "iopub.status.idle": "2025-03-24T06:41:58.445492Z",
     "shell.execute_reply": "2025-03-24T06:41:58.444337Z",
     "shell.execute_reply.started": "2025-03-24T06:41:55.532161Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 694.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 114.12 MiB is free. Process 2513 has 14.63 GiB memory in use. Of the allocated memory 14.32 GiB is allocated by PyTorch, and 176.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ad9bc73f40ea>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"VGG\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_vgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m print(\n",
      "\u001b[0;32m<ipython-input-18-9fdfcecbfb84>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(loader, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 694.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 114.12 MiB is free. Process 2513 has 14.63 GiB memory in use. Of the allocated memory 14.32 GiB is allocated by PyTorch, and 176.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "print(\"VGG\")\n",
    "train_acc = accuracy(train_loader_vgg,model)\n",
    "test_acc = accuracy(test_loader,model)\n",
    "validation_acc = accuracy(validation_loader,model)\n",
    "print(\n",
    "    f\"Train Accuracy : {train_acc}\\nTest Accuracy : {test_acc}\\nValidation Accuracy : {validation_acc}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2536476,
     "sourceId": 4305991,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
