{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4305991,"sourceType":"datasetVersion","datasetId":2536476}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Dependencies","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms, models  # datsets  , transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch.nn as nn\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:14:09.459381Z","iopub.execute_input":"2025-03-25T16:14:09.459671Z","iopub.status.idle":"2025-03-25T16:14:15.212383Z","shell.execute_reply.started":"2025-03-25T16:14:09.459642Z","shell.execute_reply":"2025-03-25T16:14:15.211739Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# For VGG16","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\ntransform2 = transforms.Compose([#vgg16 \n    transforms.Resize((299, 299)),\n    transforms.ToTensor(), # ToTensor image ko convert karta hai pixelated values ye pytorch tensor me ie [0,1]\n    transforms.Normalize(  #Normalize scale karta hai image ko [-1,1] me    \n        mean=[0.5, 0.5, 0.5],\n        std=[0.5, 0.5, 0.5]\n    )\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:14:23.282080Z","iopub.execute_input":"2025-03-25T16:14:23.282339Z","iopub.status.idle":"2025-03-25T16:14:23.286767Z","shell.execute_reply.started":"2025-03-25T16:14:23.282320Z","shell.execute_reply":"2025-03-25T16:14:23.285883Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"dataset_vgg=datasets.ImageFolder(\"/kaggle/input/mepco-tropic-leaf/MepcoTropicLeaf-V1/Database\", transform=transform2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:14:24.006141Z","iopub.execute_input":"2025-03-25T16:14:24.006394Z","iopub.status.idle":"2025-03-25T16:14:33.080484Z","shell.execute_reply.started":"2025-03-25T16:14:24.006376Z","shell.execute_reply":"2025-03-25T16:14:33.079859Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Splitting the dataset ","metadata":{}},{"cell_type":"code","source":"indices=list(range(len(dataset_vgg))) # dataset ko numerate karne ke liye\nsplit=int(np.floor(0.70*len(dataset_vgg)))\nvalidation=int(np.floor(0.60*split))\n\n# agar tmre pass 100 samples hai\n# toh split=70(ie 70% of the dataset)-> ee use hoga training and validation ke liye; remaining (30)30% used hoga as test set\n# tb validation=42 (ie 60% of the dataset)-> ee use hoga for training ke liye; remaining (28)40% used hoga as Validation set\n# toh phir training= 42%; validation= 28%; test=30%\n\nprint(f\"length of train size : {validation}\")\nprint(f\"length of validation size : {split-validation}\")\nprint(f\"length of test size : {len(dataset_vgg)-split}\")\n\nnp.random.shuffle(indices) # dataset me randomness laane ke liye\n\n# ab actual splitting\ntrain_indices, validation_indices, test_indices = (\n    indices[:validation], # [:5]->0,1,2,3,4\n    indices[validation:split],# [1:3]->1,2\n    indices[split:],# [2:]-> 2,3,4,5,........\n)\n\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalidation_sampler = SubsetRandomSampler(validation_indices)\ntest_sampler = SubsetRandomSampler(test_indices)\n\n# print(list(train_indices))\n# print(list(validation_indices))\n# print(list(test_indices))\n\n# print(list(train_sampler))\n# print(list(validation_sampler))\n# print(list(test_sampler))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:14:34.843154Z","iopub.execute_input":"2025-03-25T16:14:34.843441Z","iopub.status.idle":"2025-03-25T16:14:34.851459Z","shell.execute_reply.started":"2025-03-25T16:14:34.843418Z","shell.execute_reply":"2025-03-25T16:14:34.850473Z"}},"outputs":[{"name":"stdout","text":"length of train size : 1585\nlength of validation size : 1058\nlength of test size : 1134\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## No. of unique features","metadata":{}},{"cell_type":"code","source":"targets_size = len(dataset_vgg.class_to_idx)# finding the total unique classes and storing it\nprint(targets_size)\nprint(list(dataset_vgg.class_to_idx.keys()))\nnum_classes_list = list(dataset_vgg.class_to_idx.values())# now numerating them\nprint(num_classes_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:14:36.897980Z","iopub.execute_input":"2025-03-25T16:14:36.898248Z","iopub.status.idle":"2025-03-25T16:14:36.903382Z","shell.execute_reply.started":"2025-03-25T16:14:36.898229Z","shell.execute_reply":"2025-03-25T16:14:36.902623Z"}},"outputs":[{"name":"stdout","text":"50\n['Asthma Plant.zip', 'Avaram.zip', 'Balloon vine.zip', 'Bellyache bush (Green).zip', 'Benghal dayflower.zip', 'Big Caltrops.zip', 'Black-Honey Shrub.zip', 'Bristly Wild Grape.zip', 'Butterfly Pea.zip', 'Cape Gooseberry.zip', 'Common Wireweed.zip', 'Country Mallow.zip', 'Crown flower.zip', 'Green Chireta.zip', 'Holy Basil.zip', 'Indian CopperLeaf.zip', 'Indian Jujube.zip', 'Indian Sarsaparilla.zip', 'Indian Stinging Nettle.zip', 'Indian Thornapple.zip', 'Indian wormwood.zip', 'Ivy Gourd.zip', 'Kokilaksha.zip', 'Land Caltrops (Bindii).zip', 'Madagascar Periwinkle.zip', 'Madras Pea Pumpkin.zip', 'Malabar Catmint.zip', 'Mexican Mint.zip', 'Mexican Prickly Poppy.zip', 'Mountain Knotgrass.zip', 'Nalta Jute.zip', 'Night blooming Cereus.zip', 'Panicled Foldwing.zip', 'Prickly Chaff Flower.zip', 'Punarnava.zip', 'Purple Fruited Pea Eggplant.zip', 'Purple Tephrosia.zip', 'Rosary Pea.zip', 'Shaggy button weed.zip', 'Small Water Clover.zip', 'Spiderwisp.zip', 'Square Stalked Vine.zip', 'Stinking Passionflower.zip', 'Sweet Basil.zip', 'Sweet flag.zip', 'Tinnevelly Senna.zip', 'Trellis Vine.zip', 'Velvet bean.zip', 'coatbuttons.zip', 'heart-leaved moonseed.zip']\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Loading VGG16","metadata":{}},{"cell_type":"code","source":"model3 = models.vgg16(pretrained=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:14:38.339921Z","iopub.execute_input":"2025-03-25T16:14:38.340189Z","iopub.status.idle":"2025-03-25T16:14:42.619980Z","shell.execute_reply.started":"2025-03-25T16:14:38.340170Z","shell.execute_reply":"2025-03-25T16:14:42.619332Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 213MB/s] \n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Extracting Feature size ","metadata":{}},{"cell_type":"code","source":"n_features = model3.classifier[0].in_features #vgg16; number of input features in the first fully connected layer\nn_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:14:45.304404Z","iopub.execute_input":"2025-03-25T16:14:45.304725Z","iopub.status.idle":"2025-03-25T16:14:45.310638Z","shell.execute_reply.started":"2025-03-25T16:14:45.304698Z","shell.execute_reply":"2025-03-25T16:14:45.309600Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"25088"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Overriding the calculations to GPU if available ","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device) #checking if GPU is available\nmodel3.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:14:47.311390Z","iopub.execute_input":"2025-03-25T16:14:47.311693Z","iopub.status.idle":"2025-03-25T16:14:47.763871Z","shell.execute_reply.started":"2025-03-25T16:14:47.311671Z","shell.execute_reply":"2025-03-25T16:14:47.763180Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Optimizer and criterion for gradient descent ","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()  # this include softmax + cross entropy loss\n# calculates the loss during training, which will be later used by backpropagation to imporove the models accuracy\noptimizer = torch.optim.Adam(model3.parameters())\n#adam optimiser is used to optimise the models parameters(weights of the model) to minimise the loss and hence increase the accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:14:49.956715Z","iopub.execute_input":"2025-03-25T16:14:49.956995Z","iopub.status.idle":"2025-03-25T16:14:49.961030Z","shell.execute_reply.started":"2025-03-25T16:14:49.956975Z","shell.execute_reply":"2025-03-25T16:14:49.960092Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Actual training","metadata":{}},{"cell_type":"markdown","source":"### Data transform","metadata":{}},{"cell_type":"code","source":"data_transforms = {\n    'train_loader': transforms.Compose([\n        transforms.RandomAffine(degrees=10, translate=(0.05, 0.05), shear=5),\n        transforms.ColorJitter(hue=0.05, saturation=0.05),\n        transforms.RandomHorizontalFlip(),\n        transforms.Grayscale(num_output_channels=1),\n         transforms.RandomApply([transforms.GaussianBlur(kernel_size=7)], p=0.2),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,)),\n    ]),\n    'validation_loader': transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,)),\n    ])\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:14:51.819020Z","iopub.execute_input":"2025-03-25T16:14:51.819285Z","iopub.status.idle":"2025-03-25T16:14:51.824404Z","shell.execute_reply.started":"2025-03-25T16:14:51.819264Z","shell.execute_reply":"2025-03-25T16:14:51.823598Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### Dividing the dataset into train, test, validation batches","metadata":{}},{"cell_type":"code","source":"batch_size = 64\ntrain_loader = torch.utils.data.DataLoader(\n    dataset_vgg, batch_size=batch_size, sampler=train_sampler\n)\ntest_loader = torch.utils.data.DataLoader(\n    dataset_vgg, batch_size=batch_size, sampler=test_sampler\n)\nvalidation_loader = torch.utils.data.DataLoader(\n    dataset_vgg, batch_size=batch_size, sampler=validation_sampler\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:14:53.961819Z","iopub.execute_input":"2025-03-25T16:14:53.962091Z","iopub.status.idle":"2025-03-25T16:14:53.966551Z","shell.execute_reply.started":"2025-03-25T16:14:53.962072Z","shell.execute_reply":"2025-03-25T16:14:53.965744Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### Gradient Descent","metadata":{}},{"cell_type":"code","source":"def batch_gd(model, criterion, train_loader, test_loader, epochs):\n    train_losses = np.zeros(epochs)\n    test_losses = np.zeros(epochs)\n\n    for e in range(epochs):\n\n        t0 = datetime.now()\n        train_loss = []\n        for inputs, targets in train_loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            optimizer.zero_grad()\n            output = model(inputs)\n            loss = criterion(output, targets)\n            train_loss.append(loss.item())  # torch to numpy world\n            loss.backward()\n            optimizer.step()\n\n        train_loss = np.mean(train_loss)\n        validation_loss = []\n\n        for inputs, targets in validation_loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            output = model(inputs)\n            loss = criterion(output, targets)\n            validation_loss.append(loss.item())  # torch to numpy world\n\n        validation_loss = np.mean(validation_loss)\n        train_losses[e] = train_loss\n        dt = datetime.now() - t0\n        print(f\"Epoch : {e+1}/{epochs} Train_loss:{train_loss:.3f} Duration:{dt}\")\n\n    return train_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:14:55.314063Z","iopub.execute_input":"2025-03-25T16:14:55.314328Z","iopub.status.idle":"2025-03-25T16:14:55.320320Z","shell.execute_reply.started":"2025-03-25T16:14:55.314308Z","shell.execute_reply":"2025-03-25T16:14:55.319509Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_losses_vgg = batch_gd(model3, criterion, train_loader, validation_loader, 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:14:56.718927Z","iopub.execute_input":"2025-03-25T16:14:56.719196Z","iopub.status.idle":"2025-03-25T16:15:56.295118Z","shell.execute_reply.started":"2025-03-25T16:14:56.719177Z","shell.execute_reply":"2025-03-25T16:15:56.293757Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-2f148a4ff06c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses_vgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_gd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-4ae2d4288948>\u001b[0m in \u001b[0;36mbatch_gd\u001b[0;34m(model, criterion, train_loader, test_loader, epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# torch to numpy world\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 694.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 114.12 MiB is free. Process 3477 has 14.63 GiB memory in use. Of the allocated memory 13.59 GiB is allocated by PyTorch, and 926.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 694.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 114.12 MiB is free. Process 3477 has 14.63 GiB memory in use. Of the allocated memory 13.59 GiB is allocated by PyTorch, and 926.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":13},{"cell_type":"markdown","source":"## Loss Graph ","metadata":{}},{"cell_type":"code","source":"plt.plot(train_losses_resnet , label = 'train_loss_vgg')\nplt.xlabel('No of Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()#validation loss ke liye ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Accuracy","metadata":{}},{"cell_type":"code","source":"def accuracy(loader):\n    n_correct = 0\n    n_total = 0\n    model.cuda()\n    for inputs, targets in loader:\n        inputs, targets = inputs.cuda(), targets.cuda()\n        outputs = model(inputs)\n        #print(outputs)\n        _, predictions = torch.max(outputs, 1)\n        n_correct += (predictions == targets).sum().item()\n        n_total += targets.shape[0]\n\n    acc = n_correct / n_total\n    return acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:13:27.507204Z","iopub.execute_input":"2025-03-25T16:13:27.507590Z","iopub.status.idle":"2025-03-25T16:13:27.514006Z","shell.execute_reply.started":"2025-03-25T16:13:27.507560Z","shell.execute_reply":"2025-03-25T16:13:27.512542Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"train_acc = accuracy(train_loader)\ntest_acc = accuracy(test_loader)\nvalidation_acc = accuracy(validation_loader)\n\nprint(\n    f\"Train Accuracy : {train_acc}\\nTest Accuracy : {test_acc}\\nValidation Accuracy : {validation_acc}\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}