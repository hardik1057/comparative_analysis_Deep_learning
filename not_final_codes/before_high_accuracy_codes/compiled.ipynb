{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the transform functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transform2 = transforms.Compose([#vgg16 \n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(), # ToTensor image ko convert karta hai pixelated values ye pytorch tensor me ie [0,1]\n",
    "    transforms.Normalize(  #Normalize scale karta hai image ko [-1,1] me    \n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "\n",
    "transform3 = transforms.Compose([          #resnet\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]\n",
    "                         )\n",
    "])\n",
    "\n",
    "transform4 = transforms.Compose([          #mobilenetv2 \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing all the transform functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing each transform on a sample image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "\n",
    "# Load a sample image from the dataset\n",
    "sample_img_path = \"C:\\\\Users\\\\hardi\\\\Downloads\\\\archive\\\\MepcoTropicLeaf-V1\\\\Database\"\n",
    "sample_img = datasets.ImageFolder(sample_img_path).imgs[0][0]  # Get first image path\n",
    "img = Image.open(sample_img)\n",
    "\n",
    "print(sample_img)\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(5, 5))\n",
    "fig.suptitle('Comparing Different Transforms')\n",
    "\n",
    "# Original image\n",
    "axes[0,0].imshow(img)\n",
    "axes[0,0].set_title('Original Image')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "# Transform 2\n",
    "img_t2 = transform2(img)\n",
    "img_t2 = img_t2.permute(1,2,0).numpy()  # Convert from CxHxW to HxWxC\n",
    "img_t2 = (img_t2 * 0.5 + 0.5).clip(0, 1)  # Denormalize\n",
    "axes[0,1].imshow(img_t2)\n",
    "axes[0,1].set_title('Transform 2 (299x299)')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "# Transform 3\n",
    "img_t3 = transform3(img)\n",
    "img_t3 = img_t3.permute(1,2,0).numpy()\n",
    "img_t3 = (img_t3 * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]).clip(0, 1)  # Denormalize\n",
    "axes[1,0].imshow(img_t3)\n",
    "axes[1,0].set_title('Transform 3 (299x299)')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "# Transform 4\n",
    "img_t4 = transform4(img)\n",
    "img_t4 = img_t4.permute(1,2,0).numpy()\n",
    "img_t4 = (img_t4 * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]).clip(0, 1)  # Denormalize\n",
    "axes[1,1].imshow(img_t4)\n",
    "axes[1,1].set_title('Transform 4 (224x224)')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# dataset_vgg=datasets.ImageFolder(\"/content/drive/MyDrive/patta /archive/MepcoTropicLeaf-V1/Database\", transform=transform2)\n",
    "# dataset_mobilenet=datasets.ImageFolder(\"/content/drive/MyDrive/patta /archive/MepcoTropicLeaf-V1/Database\", transform=transform4)\n",
    "# dataset_resnet=datasets.ImageFolder(\"/content/drive/MyDrive/patta /archive/MepcoTropicLeaf-V1/Database\", transform=transform3)\n",
    "dataset_vgg=datasets.ImageFolder(\"C:\\\\Users\\\\hardi\\\\Downloads\\\\archive\\\\MepcoTropicLeaf-V1\\\\Database\", transform=transform2)\n",
    "dataset_mobilenet=datasets.ImageFolder(\"C:\\\\Users\\\\hardi\\\\Downloads\\\\archive\\\\MepcoTropicLeaf-V1\\\\Database\", transform=transform4)\n",
    "dataset_resnet=datasets.ImageFolder(\"C:\\\\Users\\\\hardi\\\\Downloads\\\\archive\\\\MepcoTropicLeaf-V1\\\\Database\", transform=transform3)\n",
    "print(dataset_vgg)\n",
    "print(dataset_mobilenet)\n",
    "print(dataset_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "indices=list(range(len(dataset_vgg))) # dataset ko numerate karne ke liye\n",
    "split=int(np.floor(0.70*len(dataset_vgg)))\n",
    "validation=int(np.floor(0.60*split))\n",
    "\n",
    "# agar tmre pass 100 samples hai\n",
    "# toh split=70(ie 70% of the dataset)-> ee use hoga training and validation ke liye; remaining (30)30% used hoga as test set\n",
    "# tb validation=42 (ie 60% of the dataset)-> ee use hoga for training ke liye; remaining (28)40% used hoga as Validation set \n",
    "# toh phir training= 42%; validation= 28%; test=30%\n",
    "\n",
    "print(f\"length of train size : {validation}\")  \n",
    "print(f\"length of validation size : {split-validation}\")  \n",
    "print(f\"length of test size : {len(dataset_vgg)-split}\")  \n",
    "\n",
    "np.random.shuffle(indices) # dataset me randomness laane ke liye\n",
    "\n",
    "# ab actual splitting \n",
    "train_indices, validation_indices, test_indices = (\n",
    "    indices[:validation], # [:5]->0,1,2,3,4\n",
    "    indices[validation:split],# [1:3]->1,2\n",
    "    indices[split:],# [2:]-> 2,3,4,5,........\n",
    ")\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler #randomly shuffles the dataset\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "validation_sampler = SubsetRandomSampler(validation_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "# print(list(train_indices))\n",
    "# print(list(validation_indices))\n",
    "# print(list(test_indices))\n",
    "\n",
    "# print(list(train_sampler))\n",
    "# print(list(validation_sampler))\n",
    "# print(list(test_sampler))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_size = len(dataset_vgg.class_to_idx)# finding the total unique classes and storing it\n",
    "print(targets_size)\n",
    "print(list(dataset_vgg.class_to_idx.keys()))\n",
    "num_classes_list = list(dataset_vgg.class_to_idx.values())# now numerating them\n",
    "print(num_classes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "model = models.vgg16(pretrained=True)#if pretrained=false, tb saare layers ko hmlog ko individually train karna hoga\n",
    "model2=models.mobilenet_v2(pretrained=True)\n",
    "model3=models.resnet18(pretrained=True)\n",
    "\n",
    "# model \n",
    "# model2\n",
    "# model3 \n",
    "\n",
    "for params in model3.parameters(): \n",
    "   params.requires_grad = True\n",
    "# resnet18 ke saare parameters ko trainable bana rhe hai; resnet ka feature extraction acha kaam karra hai isliye use krre plus accuracy bhi increase ho rha  \n",
    "# mobilenet aur vgg complex models hai (more param and layers), agar isko(function) use kare toh model overfit ho sakta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting feature size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = model.classifier[0].in_features #vgg16; number of input features in the first fully connected layer\n",
    "print(1, n_features)\n",
    "n_features = model2.classifier[1].in_features #mobilenet; number of input features in the first fully connected layer\n",
    "print(2, n_features)\n",
    "n_features = model3.conv1.in_channels #resnet18; number of input features in the first convolutional layer\n",
    "print(3, n_features)\n",
    "\n",
    "# ee kyu krre?-> taaki pata chale ki input and output features pata chale\n",
    "# Last layer change karke model ko apne data pe train karre hai.  \n",
    "# Pehle wali layers ko rakhne ka fayda->  \n",
    "# Ye layers already trained hota h aur feature extraction achha kar leta h.  \n",
    "# Sirf last layer train karne se kam computation time lagega.  \n",
    "# Kam data hone par bhi model achha perform karega, kyunki pehle se trained layers use ho rahi hain.  \n",
    "# Isko *Transfer Learning kehte hain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-riding the calculations to GPU(if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) #checking if GPU is available\n",
    "model.to(device)\n",
    "model2.to(device)\n",
    "model3.to(device)#shifting the model to 'device' for computing\n",
    "\n",
    "#summarizing the layers of all models; helps validate the model before training, avoiding errors later.\n",
    "\n",
    "# from torchsummary import summary\n",
    "# print(1, summary(model, (3, 224, 224)))\n",
    "# print(2, summary(model2, (3, 224, 224)))\n",
    "# print(3, summary(model3, (3, 224, 224))) \n",
    "\n",
    "#output shape [-1,c,h,w]\n",
    "#c->no of filters/ channels\n",
    "#h,w-> feature map size after operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss()  # this include softmax + cross entropy loss\n",
    "# calculates the loss during training, which will be later used by backpropagation to imporove the models accuracy\n",
    "optimizer_vgg = torch.optim.Adam(model.parameters())  \n",
    "optimizer_mobilenet= torch.optim.Adam(model2.parameters()) \n",
    "optimizer_resnet = torch.optim.Adam(model3.parameters())  \n",
    "#adam optimiser is used to optimise the models parameters(weights of the model) to minimise the loss and hence increase the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train_loader': transforms.Compose([\n",
    "        transforms.RandomAffine(degrees=10, translate=(0.05, 0.05), shear=5) , # image ko randomly rotate karne ke liye\n",
    "        transforms.ColorJitter(hue=0.05, saturation=0.05), # naam jo suggest karta hai\n",
    "        transforms.RandomHorizontalFlip(), #randomly image ko flip kar deta hai 50% probability saath\n",
    "        transforms.Grayscale(num_output_channels=1), #image is converted to black and white when =1; when=3 it is converted to fake RGB\n",
    "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=7)], p=0.2), # randomly applies Gaussian blur with probability=20%;\n",
    "                                                                                 # kernel size=7->moderate blur; 3->light blur; 15->heavy blur\n",
    "        transforms.ToTensor(),#image ko convert karta hai pixelated values ye pytorch tensor me ie [0,1]\n",
    "        transforms.Normalize((0.5,), (0.5,)),#pixelated values from [0,1] to [-1,1]\n",
    "    ]),\n",
    "    'validation_loader': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "#balances training speed and memory usage, as smaller trains slow and require less gpu, while larger batches train faster but require more GPU memory.\n",
    "#vgg\n",
    "train_loader_vgg = torch.utils.data.DataLoader(dataset_vgg, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader_vgg = torch.utils.data.DataLoader(dataset_vgg, batch_size=batch_size, sampler=test_sampler)\n",
    "validation_loader_vgg = torch.utils.data.DataLoader(dataset_vgg, batch_size=batch_size, sampler=validation_sampler)\n",
    "\n",
    "#mobilenet\n",
    "train_loader_mobilenet = torch.utils.data.DataLoader(dataset_mobilenet, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader_mobilenet = torch.utils.data.DataLoader(dataset_mobilenet, batch_size=batch_size, sampler=test_sampler)\n",
    "validation_loader_mobilenet = torch.utils.data.DataLoader(dataset_mobilenet, batch_size=batch_size, sampler=validation_sampler)\n",
    "\n",
    "#resnet\n",
    "train_loader_resnet = torch.utils.data.DataLoader(dataset_resnet, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader_resnet = torch.utils.data.DataLoader(dataset_resnet, batch_size=batch_size, sampler=test_sampler)\n",
    "validation_loader_resnet = torch.utils.data.DataLoader(dataset_resnet, batch_size=batch_size, sampler=validation_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def batch_gd(model1, model2, model3, criterion, train_loader_vgg, train_loader_mobilenet, train_loader_resnet, \n",
    "             validation_loader_vgg, validation_loader_mobilenet, validation_loader_resnet, epochs):\n",
    "    # Initialize loss arrays for each model\n",
    "    train_losses_vgg = np.zeros(epochs)\n",
    "    train_losses_mobilenet = np.zeros(epochs)\n",
    "    train_losses_resnet = np.zeros(epochs)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        t0 = datetime.now()\n",
    "        \n",
    "        # Train VGG16 model\n",
    "        train_loss_vgg = []\n",
    "        for inputs, targets in train_loader_vgg:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer_vgg.zero_grad()\n",
    "            output = model1(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            train_loss_vgg.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer_vgg.step()\n",
    "        \n",
    "        # Calculate average VGG loss\n",
    "        train_loss_vgg_avg = np.mean(train_loss_vgg)\n",
    "        train_losses_vgg[e] = train_loss_vgg_avg\n",
    "        \n",
    "        # Validate VGG16 model\n",
    "        validation_loss_vgg = []\n",
    "        for inputs, targets in validation_loader_vgg:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            output = model1(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            validation_loss_vgg.append(loss.item())\n",
    "        validation_loss_vgg_avg = np.mean(validation_loss_vgg)\n",
    "        \n",
    "        # Train MobileNetV2 model\n",
    "        train_loss_mobilenet = []\n",
    "        for inputs, targets in train_loader_mobilenet:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer_mobilenet.zero_grad()\n",
    "            output = model2(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            train_loss_mobilenet.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer_mobilenet.step()\n",
    "        \n",
    "        # Calculate average MobileNet loss\n",
    "        train_loss_mobilenet_avg = np.mean(train_loss_mobilenet)\n",
    "        train_losses_mobilenet[e] = train_loss_mobilenet_avg\n",
    "        \n",
    "        # Validate MobileNetV2 model\n",
    "        validation_loss_mobilenet = []\n",
    "        for inputs, targets in validation_loader_mobilenet:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            output = model2(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            validation_loss_mobilenet.append(loss.item())\n",
    "        validation_loss_mobilenet_avg = np.mean(validation_loss_mobilenet)\n",
    "        \n",
    "        # Train ResNet18 model\n",
    "        train_loss_resnet = []\n",
    "        for inputs, targets in train_loader_resnet:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer_resnet.zero_grad()\n",
    "            output = model3(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            train_loss_resnet.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer_resnet.step()\n",
    "        \n",
    "        # Calculate average ResNet loss\n",
    "        train_loss_resnet_avg = np.mean(train_loss_resnet)\n",
    "        train_losses_resnet[e] = train_loss_resnet_avg\n",
    "        \n",
    "        # Validate ResNet18 model\n",
    "        validation_loss_resnet = []\n",
    "        for inputs, targets in validation_loader_resnet:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            output = model3(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            validation_loss_resnet.append(loss.item())\n",
    "        validation_loss_resnet_avg = np.mean(validation_loss_resnet)\n",
    "        \n",
    "        dt = datetime.now() - t0\n",
    "        \n",
    "        # Print results for each model\n",
    "        print(f\"Epoch : {e+1}/{epochs}\")\n",
    "        print(f\"VGG16 - Train Loss: {train_loss_vgg_avg:.3f}, Validation Loss: {validation_loss_vgg_avg:.3f}\")\n",
    "        print(f\"MobileNetV2 - Train Loss: {train_loss_mobilenet_avg:.3f}, Validation Loss: {validation_loss_mobilenet_avg:.3f}\")\n",
    "        print(f\"ResNet18 - Train Loss: {train_loss_resnet_avg:.3f}, Validation Loss: {validation_loss_resnet_avg:.3f}\")\n",
    "        print(f\"Duration: {dt}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    return train_losses_vgg, train_losses_mobilenet, train_losses_resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asli kaam ab hoga "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_vgg, train_losses_mobilenet, train_losses_resnet = batch_gd(\n",
    "    model, model2, model3, \n",
    "    criterion, \n",
    "    train_loader_vgg, train_loader_mobilenet, train_loader_resnet,\n",
    "    validation_loader_vgg, validation_loader_mobilenet, validation_loader_resnet, \n",
    "    10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def accuracy(model, loader):\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    model.cuda()\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        outputs = model(inputs)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_correct += (predictions == targets).sum().item()\n",
    "        n_total += targets.shape[0]\n",
    "\n",
    "    acc = n_correct / n_total\n",
    "    return acc\n",
    "\n",
    "# Calculate accuracy for VGG16\n",
    "train_acc_vgg = accuracy(model, train_loader_vgg)\n",
    "test_acc_vgg = accuracy(model, test_loader_vgg)\n",
    "validation_acc_vgg = accuracy(model, validation_loader_vgg)\n",
    "\n",
    "# Calculate accuracy for MobileNetV2\n",
    "train_acc_mobilenet = accuracy(model2, train_loader_mobilenet)\n",
    "test_acc_mobilenet = accuracy(model2, test_loader_mobilenet)\n",
    "validation_acc_mobilenet = accuracy(model2, validation_loader_mobilenet)\n",
    "\n",
    "# Calculate accuracy for ResNet18\n",
    "train_acc_resnet = accuracy(model3, train_loader_resnet)\n",
    "test_acc_resnet = accuracy(model3, test_loader_resnet)\n",
    "validation_acc_resnet = accuracy(model3, validation_loader_resnet)\n",
    "\n",
    "# Print accuracy for each model\n",
    "print(\"VGG16 Accuracy:\")\n",
    "print(f\"Train Accuracy: {train_acc_vgg:.4f}\\nTest Accuracy: {test_acc_vgg:.4f}\\nValidation Accuracy: {validation_acc_vgg:.4f}\")\n",
    "print(\"\\nMobileNetV2 Accuracy:\")\n",
    "print(f\"Train Accuracy: {train_acc_mobilenet:.4f}\\nTest Accuracy: {test_acc_mobilenet:.4f}\\nValidation Accuracy: {validation_acc_mobilenet:.4f}\")\n",
    "print(\"\\nResNet18 Accuracy:\")\n",
    "print(f\"Train Accuracy: {train_acc_resnet:.4f}\\nTest Accuracy: {test_acc_resnet:.4f}\\nValidation Accuracy: {validation_acc_resnet:.4f}\")\n",
    "\n",
    "# Plot losses for all models\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses_vgg, label='VGG16 Train Loss')\n",
    "plt.plot(train_losses_mobilenet, label='MobileNetV2 Train Loss')\n",
    "plt.plot(train_losses_resnet, label='ResNet18 Train Loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Loss Comparison')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
